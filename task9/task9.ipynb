{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "seeing-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import NewsNERTagger\n",
    "from natasha import MorphVocab, NewsEmbedding, NewsMorphTagger\n",
    "from natasha import Doc, Segmenter\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "american-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "analyzer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "literary-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_tagger = NewsMorphTagger(embedding)\n",
    "morph_vocab = MorphVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "scientific-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/corpus_as_dict.json\") as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "charged-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(docs.keys())\n",
    "texts = list(docs.values())\n",
    "df = pd.DataFrame.from_dict({'title':titles, 'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prepared-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Ледник</td>\n",
       "      <td>Ледник — масса льда преимущественно атмосферно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Дифферент</td>\n",
       "      <td>Дифферент — морской термин, разница осадок суд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Скакалка</td>\n",
       "      <td>Скакалка — спортивный снаряд для физических уп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Двойное дно</td>\n",
       "      <td>Двойное дно — кораблестроительный термин, част...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Титаник. Легенда продолжается</td>\n",
       "      <td>«Титаник. Легенда продолжается» — комедийный с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "141                         Ледник   \n",
       "78                       Дифферент   \n",
       "268                       Скакалка   \n",
       "72                     Двойное дно   \n",
       "300  Титаник. Легенда продолжается   \n",
       "\n",
       "                                                  text  \n",
       "141  Ледник — масса льда преимущественно атмосферно...  \n",
       "78   Дифферент — морской термин, разница осадок суд...  \n",
       "268  Скакалка — спортивный снаряд для физических уп...  \n",
       "72   Двойное дно — кораблестроительный термин, част...  \n",
       "300  «Титаник. Легенда продолжается» — комедийный с...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "front-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(transcript):\n",
    "  script = Doc(re.sub(r'\\((.*?)\\)', \"\", transcript))\n",
    "  script.segment(segmenter)\n",
    "  script.tag_morph(morph_tagger)\n",
    "  for token in script.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "  script.tag_ner(ner_tagger)\n",
    "  for span in script.spans:\n",
    "    span.normalize(morph_vocab)\n",
    "  named_ents = [(i.text, i.type, i.normal) for i in script.spans]\n",
    "  normed_ents = []\n",
    "  for word, tag, norm in named_ents:\n",
    "    if len(word.split()) == 1 and tag == \"LOC\":\n",
    "      for gram in range(len(analyzer.parse(word))):\n",
    "        if \"Geox\" in analyzer.parse(word)[gram].tag:\n",
    "          normed_ents.append((analyzer.parse(word)[gram].normal_form))\n",
    "          break\n",
    "        elif gram == len(analyzer.parse(word)) - 1:\n",
    "          normed_ents.append((norm.lower().strip(\".,!?;-\")))\n",
    "    else:\n",
    "      normed_ents.append((norm.lower().strip(\".,!?;-\")))\n",
    "  return sorted(normed_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "natural-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"named_entities\"] = df.apply(lambda row: get_ner(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "prepared-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Бифштекс</td>\n",
       "      <td>Бифштекс, стейк-филе — блюдо из жареной говяди...</td>\n",
       "      <td>[бифштекс, британия, сша, сша, сша]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Машинный телеграф</td>\n",
       "      <td>Машинный телеграф — устройство для передачи из...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Углекислый газ</td>\n",
       "      <td>Диоксид углерода или двуокись углерода — бесцв...</td>\n",
       "      <td>[земля, земля, земля, земля, земля, земля, сол...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                                               text  \\\n",
       "27            Бифштекс  Бифштекс, стейк-филе — блюдо из жареной говяди...   \n",
       "159  Машинный телеграф  Машинный телеграф — устройство для передачи из...   \n",
       "316     Углекислый газ  Диоксид углерода или двуокись углерода — бесцв...   \n",
       "\n",
       "                                        named_entities  \n",
       "27                 [бифштекс, британия, сша, сша, сша]  \n",
       "159                                                 []  \n",
       "316  [земля, земля, земля, земля, земля, земля, сол...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convenient-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ner = [i for i in df.index.values if df.named_entities[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ancient-adult",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 363)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(has_ner), df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ordinary-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = df[df.index.isin(has_ner)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "arranged-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "recovered-column",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1758, 955)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_voc = []\n",
    "for row in df_ner.named_entities.tolist():\n",
    "  ner_voc.extend(row)\n",
    "len(ner_voc), len(set(ner_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "civic-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(set(ner_voc))\n",
    "corpus = df_ner.named_entities.apply(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "southwest-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
    "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "X = pipe.fit_transform(corpus)\n",
    "km = KMeans(n_clusters=30, init='k-means++', max_iter=600, \n",
    "            algorithm=\"full\", precompute_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "correct-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexanderlakiza/.virtualenvs/cs224/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', max_iter=600, n_clusters=30, precompute_distances=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "wanted-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12205426569682176\n",
      "1.2836337163552074\n"
     ]
    }
   ],
   "source": [
    "print(metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "print(metrics.davies_bouldin_score(X.toarray(), km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "biological-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-20dc8af91091>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ner[\"label\"] = km.predict(X)\n"
     ]
    }
   ],
   "source": [
    "df_ner[\"label\"] = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "drawn-estate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     151\n",
       "6       9\n",
       "1       8\n",
       "16      7\n",
       "5       4\n",
       "23      3\n",
       "8       3\n",
       "9       3\n",
       "13      3\n",
       "21      2\n",
       "20      2\n",
       "19      2\n",
       "18      2\n",
       "17      2\n",
       "15      2\n",
       "10      2\n",
       "7       2\n",
       "4       2\n",
       "3       2\n",
       "27      2\n",
       "26      1\n",
       "24      1\n",
       "28      1\n",
       "25      1\n",
       "0       1\n",
       "22      1\n",
       "14      1\n",
       "12      1\n",
       "11      1\n",
       "29      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "intended-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Вокзал Сен-Лазар</td>\n",
       "      <td>Вокзал Сен-Лазар — одна из шести крупных голов...</td>\n",
       "      <td>[европа, иль-де-франс, париж, сен-лазар, сен-л...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Национальная библиотека Франции</td>\n",
       "      <td>Национальная библиотека Франции — библиотека в...</td>\n",
       "      <td>[европа, национальная библиотека, париж, париж...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Париж</td>\n",
       "      <td>Париж — столица и крупнейший город Франции, а ...</td>\n",
       "      <td>[большой париж, версаль, евросоюз, иль-де-фран...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "52                  Вокзал Сен-Лазар   \n",
       "186  Национальная библиотека Франции   \n",
       "205                            Париж   \n",
       "\n",
       "                                                  text  \\\n",
       "52   Вокзал Сен-Лазар — одна из шести крупных голов...   \n",
       "186  Национальная библиотека Франции — библиотека в...   \n",
       "205  Париж — столица и крупнейший город Франции, а ...   \n",
       "\n",
       "                                        named_entities  label  \n",
       "52   [европа, иль-де-франс, париж, сен-лазар, сен-л...      8  \n",
       "186  [европа, национальная библиотека, париж, париж...      8  \n",
       "205  [большой париж, версаль, евросоюз, иль-де-фран...      8  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner.query(\"label == 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "common-valve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: бангор белфаст керрикфергус керрикфергусский холивуд антрим даун ирландия хердман келтроу\n",
      "Cluster 1: сша конгресс америка nautilus вмс штат бифштекс британия bloomberg swift\n",
      "Cluster 2: европа канада сша азия атлантический россия англия великобритания северная австралия\n",
      "Cluster 3: атлантика северная азовское евразия шпицберген черное америка атлантический жоау фернандеша лэврадур жан кальвин\n",
      "Cluster 4: пасленовые паслен японское море ж. б. ламарком залив белфаст зал слава закавказье жюль мишле жюль ардуэн-мансар жоау фернандеша лэврадур\n",
      "Cluster 5: россия российская англия сша эстония ленинград нева снг кронштадт эрмитаж\n",
      "Cluster 6: ирландия великобритания англия лондон северная шотландия уэльс уайтхолл европа белфаст\n",
      "Cluster 7: америка индия северная гренландия земля бермуды микелон австралия канада сша\n",
      "Cluster 8: париж франция сена европа ришелье паризии сите евросоюз версаль юнеско\n",
      "Cluster 9: испания мадрид европа африка португалия андорра марокко канарские гибралтар нато\n",
      "Cluster 10: ближний восток изюм средиземноморье жоау фернандеша лэврадур ж. картье жаклин жан кальвин женева японское море\n",
      "Cluster 11: ют японское море ж. б. ламарком запад заморская территория залив белфаст зал слава закавказье жюль мишле жюль ардуэн-мансар\n",
      "Cluster 12: блохи японское море ж. б. ламарком запад заморская территория залив белфаст зал слава закавказье жюль мишле жюль ардуэн-мансар\n",
      "Cluster 13: великобритания манш франция евротоннель георг южная ирландия атлантический залив белфаст зал слава\n",
      "Cluster 14: цитрус японское море ж. б. ламарком запад заморская территория залив белфаст зал слава закавказье жюль мишле жюль ардуэн-мансар\n",
      "Cluster 15: стрип невад кларк сша парадайз даунтаун мохаве японское море жоау фернандеша лэврадур жан кальвин\n",
      "Cluster 16: земля российская солнце луна венера меркурий арктика марс жоау фернандеша лэврадур жюль ардуэн-мансар\n",
      "Cluster 17: луна солнце земля тейи марс японское море ж. картье жаклин жан кальвин женева\n",
      "Cluster 18: саутгемптон манш уайт спитхед портсмут великобритания женева ж. б. ламарком ж. картье жаклин\n",
      "Cluster 19: лабрадор гренландия атлантический ньюфаундленд баффина атлантика европа женева западное полушарие западная европа\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = pipe[0].get_feature_names()\n",
    "for i in range(20):\n",
    "  print(\"Cluster %d:\" % i, end='')\n",
    "  for ind in order_centroids[i, :10]:\n",
    "    print(' %s' % terms[ind], end='')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224",
   "language": "python",
   "name": "cs224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
